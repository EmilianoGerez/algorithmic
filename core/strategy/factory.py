"""
Strategy Factory for Phase 8 Integration

This module provides the StrategyFactory that wires together all Phase 1-7 components:
- Indicators → Detectors → ZoneWatcher → FSM → Risk → PaperBroker

The factory builds a complete strategy pipeline from configuration and coordinates
all components for deterministic backtesting.
"""

from __future__ import annotations

import logging
from contextlib import suppress
from dataclasses import dataclass
from datetime import datetime, timedelta
from typing import Any

from core.clock import get_clock
from core.detectors.fvg import FVGDetector
from core.entities import Candle
from core.indicators.pack import IndicatorPack
from core.risk.config import RiskModel
from core.risk.manager import RiskManager
from core.strategy import (
    OverlapDetector,
    PoolManager,
    PoolRegistry,
    TimeAggregator,
    ZoneWatcher,
    ZoneWatcherConfig,
)
from services.metrics import MetricsCollector, measure_operation

logger = logging.getLogger(__name__)


@dataclass
class HTFStack:
    """Container for HTF strategy components with lifecycle management."""

    pool_registry: Any = None
    overlap_detector: Any = None
    pool_manager: Any = None
    zone_watcher: Any = None
    detectors: list[Any] | None = None
    time_aggregators: dict[str, Any] | None = None

    def __post_init__(self) -> None:
        """Initialize list and dict fields after construction."""
        if self.detectors is None:
            self.detectors = []
        if self.time_aggregators is None:
            self.time_aggregators = {}

    def shutdown(self) -> None:
        """Clean shutdown for all components."""
        for comp in [
            self.pool_registry,
            self.overlap_detector,
            self.pool_manager,
            self.zone_watcher,
        ]:
            if hasattr(comp, "shutdown"):
                comp.shutdown()

        if self.detectors:
            for detector in self.detectors:
                if hasattr(detector, "shutdown"):
                    detector.shutdown()

        if self.time_aggregators:
            for aggregator in self.time_aggregators.values():
                if hasattr(aggregator, "shutdown"):
                    aggregator.shutdown()


logger = logging.getLogger(__name__)


class TradingSignal:
    """Signal generated by the strategy FSM when conditions are met."""

    def __init__(
        self,
        symbol: str,
        side: str,
        entry_price: float,
        stop_loss: float,
        take_profit: float,
        size: float,
        **kwargs: Any,
    ) -> None:
        """Initialize trading signal.

        Args:
            symbol: Trading symbol
            side: "buy" or "sell"
            entry_price: Entry price level
            stop_loss: Stop loss price
            take_profit: Take profit price
            size: Position size
            timestamp: Signal timestamp
            reason: Signal generation reason
        """
        self.symbol = symbol
        self.side = side
        self.entry_price = entry_price
        self.stop_loss = stop_loss
        self.take_profit = take_profit
        self.size = size
        self.timestamp = kwargs.get("timestamp")
        self.reason = kwargs.get("reason", "signal generated")

    def __repr__(self) -> str:
        return (
            f"TradingSignal({self.side} {self.size} {self.symbol} @ {self.entry_price})"
        )


class MockZoneWatcher:
    """Mock Zone Watcher for Phase 8 testing."""

    def __init__(self, config: Any, risk_manager: Any = None) -> None:
        self.config = config
        self.risk_manager = risk_manager
        self.last_signal_time: datetime | None = None

    def update(self, candle: Candle, indicators: IndicatorPack) -> TradingSignal | None:
        """Check for zone entries and generate signals.

        Args:
            candle: Current market candle
            indicators: Current indicator snapshot

        Returns:
            TradingSignal if conditions met, None otherwise
        """
        # Enhanced signal logic: generate signals based on multiple conditions
        ema21 = indicators.ema21.value
        ema50 = indicators.ema50.value

        if ema21 is None or ema50 is None:
            return None

        # Check cooldown period (reduced to 5 minutes for more signals)
        if (
            self.last_signal_time is not None
            and (candle.ts - self.last_signal_time).total_seconds() < 300
        ):
            return None

        # Simplified signal conditions for testing - just need EMAs to be populated
        # 1. Price above EMA21 (simplified bullish condition)
        # 2. EMA21 > EMA50 (trend condition)
        if ema21 is not None and ema50 is not None:
            price_above_ema21 = candle.close > ema21
            ema21_above_ema50 = ema21 > ema50

            # Debug logging for signal conditions
            print(
                f"DEBUG MockZoneWatcher: close={candle.close}, ema21={ema21}, ema50={ema50}"
            )
            print(
                f"  price_above_ema21: {price_above_ema21}, ema21_above_ema50: {ema21_above_ema50}"
            )

            if price_above_ema21 and ema21_above_ema50:
                self.last_signal_time = candle.ts
                print("  SIGNAL CONDITIONS MET! Generating signal...")

                # Calculate signal parameters using risk manager's tp_rr if available
                entry = candle.close
                atr = abs(candle.high - candle.low)  # Simple ATR approximation

                if self.risk_manager is not None:
                    # Use risk manager's tp_rr parameter for consistent calculations
                    atr_distance = atr * 1.5  # Base ATR distance for SL
                    stop_loss = entry - atr_distance
                    take_profit = entry + (
                        atr_distance * self.risk_manager.config.tp_rr
                    )
                else:
                    # Fallback to manual calculation - use config tp_rr instead of hardcoded value
                    sl_atr_multiple = getattr(self.config.risk, "sl_atr_multiple", 1.5)
                    tp_rr = getattr(self.config.risk, "tp_rr", 2.0)
                    atr_distance = atr * sl_atr_multiple
                    stop_loss = entry - atr_distance
                    take_profit = entry + (atr_distance * tp_rr)

                print(
                    f"  Creating TradingSignal: entry={entry}, sl={stop_loss}, tp={take_profit}"
                )

                signal = TradingSignal(
                    symbol=self.config.strategy.symbol,
                    side="buy",
                    entry_price=entry,
                    stop_loss=stop_loss,
                    take_profit=take_profit,
                    size=100.0,  # Will be sized by RiskManager
                    timestamp=candle.ts,
                    reason="EMA_momentum_bullish",
                )

                print(f"  Signal created successfully: {signal}")
                return signal

        # No signal conditions met
        return None


class MockRiskManager:
    """Mock Risk Manager for position sizing."""

    def __init__(self, config: Any) -> None:
        self.config = config
        # Access nested risk configuration
        if (
            hasattr(config, "execution")
            and hasattr(config.execution, "risk")
            and hasattr(config.execution.risk, "risk_per_trade")
        ):
            self.risk_per_trade = config.execution.risk.risk_per_trade
        elif hasattr(config, "risk") and hasattr(config.risk, "risk_per_trade"):
            self.risk_per_trade = config.risk.risk_per_trade
        else:
            self.risk_per_trade = 0.01  # Default 1% risk

    def size_position(self, signal: TradingSignal, account_balance: float) -> float:
        """Calculate position size based on risk parameters.

        Args:
            signal: Trading signal with price levels
            account_balance: Current account balance

        Returns:
            Position size in base currency
        """
        # Calculate risk amount
        risk_amount = account_balance * self.risk_per_trade

        # Calculate distance to stop loss
        if signal.side == "buy":
            risk_per_unit = signal.entry_price - signal.stop_loss
        else:
            risk_per_unit = signal.stop_loss - signal.entry_price

        if risk_per_unit <= 0:
            return 0.0

        # Calculate position size
        position_size = risk_amount / risk_per_unit

        # Apply maximum position size limit if configured
        max_size_attr = getattr(self.config, "max_position_size", None)
        max_size: float = (
            float(max_size_attr) if max_size_attr is not None else float("inf")
        )
        result: float = min(float(position_size), max_size)
        return result


class MockPaperBroker:
    """Mock Paper Broker for trade execution and tracking."""

    def __init__(
        self, config: Any, metrics_collector: MetricsCollector | None = None
    ) -> None:
        self.config = config
        self.metrics_collector = metrics_collector
        self.balance: float
        # Access nested account configuration
        if hasattr(config, "account") and hasattr(config.account, "initial_balance"):
            self.balance = float(config.account.initial_balance)
        else:
            self.balance = 10000.0  # Default balance
        self.positions: dict[str, Any] = {}
        self.trades: list[dict[str, Any]] = []
        self.trade_id = 0

        # Position management settings
        self.max_concurrent_positions = (
            getattr(config.account, "max_positions", 5)
            if hasattr(config, "account")
            else 5
        )
        self.max_exposure_pct = 0.8  # Maximum 80% of balance in positions
        self.allow_symbol_duplicates = False  # One position per symbol

        # Slippage configuration
        if hasattr(config, "execution") and hasattr(config.execution, "slippage"):
            self.slippage_entry = getattr(config.execution.slippage, "entry_pct", 0.0)
            self.slippage_exit = getattr(config.execution.slippage, "exit_pct", 0.0)
        else:
            self.slippage_entry = 0.0
            self.slippage_exit = 0.0

        logger.info(
            f"MockPaperBroker initialized with slippage: entry={self.slippage_entry:.4f}%, exit={self.slippage_exit:.4f}%"
        )

    def _apply_slippage(self, price: float, side: str, is_entry: bool) -> float:
        """Apply slippage to execution price.

        Args:
            price: Original price
            side: "buy" or "sell"
            is_entry: True for entry, False for exit

        Returns:
            Price adjusted for slippage
        """
        slippage_pct = self.slippage_entry if is_entry else self.slippage_exit

        if slippage_pct == 0.0:
            return price

        # Slippage always makes execution worse:
        # For buys: pay more (positive slippage)
        # For sells: receive less (negative slippage)
        if side == "buy":
            return price * (1 + slippage_pct)
        else:  # sell
            return price * (1 - slippage_pct)

    def submit_order(self, signal: TradingSignal, size: float) -> str | None:
        """Submit order to paper broker.

        Args:
            signal: Trading signal
            size: Calculated position size

        Returns:
            Trade ID or None if rejected
        """
        # Position management checks
        if not self._validate_new_position(signal, size):
            logger.warning(f"Position rejected by position management: {signal.symbol}")
            return None

        self.trade_id += 1
        trade_id = f"trade_{self.trade_id}"

        # Apply entry slippage to execution price
        execution_price = self._apply_slippage(
            signal.entry_price, signal.side, is_entry=True
        )

        # Apply commission
        if hasattr(self.config, "account") and hasattr(
            self.config.account, "commission"
        ):
            commission_rate = self.config.account.commission
        else:
            commission_rate = (
                0.0001  # Default 0.01% - more realistic for crypto futures
            )
        commission = size * execution_price * commission_rate
        self.balance -= commission

        # Record trade with slipped execution price
        trade = {
            "id": trade_id,
            "symbol": signal.symbol,
            "side": signal.side,
            "size": size,
            "entry_price": execution_price,  # Use slipped price for PnL calculation
            "original_entry_price": signal.entry_price,  # Keep original for analysis
            "stop_loss": signal.stop_loss,
            "take_profit": signal.take_profit,
            "entry_time": signal.timestamp,
            "commission": commission,
            "status": "open",
            "exit_price": None,
            "exit_time": None,
            "pnl": 0.0,
            "entry_slippage": execution_price
            - signal.entry_price,  # Track slippage cost
        }

        self.trades.append(trade)
        self.positions[trade_id] = trade

        # Calculate risk-reward ratio using slipped entry price
        rr = (
            (signal.take_profit - execution_price)
            / (execution_price - signal.stop_loss)
            if signal.side == "buy"
            else (execution_price - signal.take_profit)
            / (signal.stop_loss - execution_price)
        )

        logger.info(
            f"TRADE_OPENED trade_id={trade_id} side={signal.side} "
            f"original_entry={signal.entry_price:.2f} slipped_entry={execution_price:.2f} "
            f"slippage={execution_price - signal.entry_price:.4f} "
            f"stop={signal.stop_loss:.2f} tp={signal.take_profit:.2f} rr={rr:.2f} size={size:.2f}"
        )
        return trade_id

    def update_market_data(self, candle: Candle) -> None:
        """Update broker with latest market data.

        Args:
            candle: Current market candle
        """
        # Update positions with current market data
        self.update_positions(candle)

    def update_positions(self, candle: Candle) -> None:
        """Update open positions with current market data.

        Args:
            candle: Current market candle
        """
        closed_trades = []

        for trade_id, trade in self.positions.items():
            if trade["status"] != "open":
                continue

            current_price = candle.close

            # Check stop loss and take profit
            if trade["side"] == "buy":
                if current_price <= trade["stop_loss"]:
                    # Stop loss hit
                    self._close_trade(trade, current_price, candle.ts, "stop_loss")
                    closed_trades.append(trade_id)
                elif current_price >= trade["take_profit"]:
                    # Take profit hit
                    self._close_trade(trade, current_price, candle.ts, "take_profit")
                    closed_trades.append(trade_id)
            else:  # sell
                if current_price >= trade["stop_loss"]:
                    # Stop loss hit
                    self._close_trade(trade, current_price, candle.ts, "stop_loss")
                    closed_trades.append(trade_id)
                elif current_price <= trade["take_profit"]:
                    # Take profit hit
                    self._close_trade(trade, current_price, candle.ts, "take_profit")
                    closed_trades.append(trade_id)

        # Remove closed trades from positions
        for trade_id in closed_trades:
            del self.positions[trade_id]

    def _close_trade(
        self, trade: dict[str, Any], exit_price: float, exit_time: Any, reason: str
    ) -> None:
        """Close a trade and calculate PnL.

        Args:
            trade: Trade dictionary
            exit_price: Exit price (market price)
            exit_time: Exit timestamp
            reason: Closure reason
        """
        # Apply exit slippage to the actual execution price
        # When closing a position, we do the opposite operation:
        # - Closing a BUY position = SELL order (should get worse price, i.e., lower)
        # - Closing a SELL position = BUY order (should get worse price, i.e., higher)
        exit_side = "sell" if trade["side"] == "buy" else "buy"
        slipped_exit_price = self._apply_slippage(exit_price, exit_side, is_entry=False)

        # Calculate PnL using slipped exit price
        if trade["side"] == "buy":
            pnl = (slipped_exit_price - trade["entry_price"]) * trade["size"]
        else:
            pnl = (trade["entry_price"] - slipped_exit_price) * trade["size"]

        # Apply commission on exit using slipped price
        if hasattr(self.config, "account") and hasattr(
            self.config.account, "commission"
        ):
            commission_rate = self.config.account.commission
        else:
            commission_rate = (
                0.0001  # Default 0.01% - more realistic for crypto futures
            )
        exit_commission = trade["size"] * slipped_exit_price * commission_rate
        pnl -= exit_commission

        # Update trade record
        trade["exit_price"] = slipped_exit_price  # Use slipped price for PnL
        trade["original_exit_price"] = exit_price  # Keep original for analysis
        trade["exit_time"] = exit_time
        trade["pnl"] = pnl
        trade["status"] = reason
        trade["exit_commission"] = exit_commission
        trade["exit_slippage"] = slipped_exit_price - exit_price  # Track exit slippage

        # Update balance
        self.balance += pnl

        # Find and update the trade in the trades list
        for i, stored_trade in enumerate(self.trades):
            if stored_trade["id"] == trade["id"]:
                self.trades[i] = trade.copy()
                break

        # Record trade with metrics collector
        if self.metrics_collector:
            duration_minutes = (exit_time - trade["entry_time"]).total_seconds() / 60.0
            total_fees = trade["commission"] + trade.get("exit_commission", 0)
            total_slippage = trade.get("entry_slippage", 0) + trade.get(
                "exit_slippage", 0
            )
            self.metrics_collector.record_trade(
                pnl=pnl,
                fees=total_fees,
                duration_minutes=duration_minutes,
                position_size=abs(trade["size"]),
            )

        # Log trade closure with structured format for analysis
        win_or_loss = "WIN" if pnl > 0 else "LOSS"
        total_slippage = trade.get("entry_slippage", 0) + trade.get("exit_slippage", 0)
        logger.info(
            f"TRADE_CLOSED trade_id={trade['id']} side={trade['side']} "
            f"entry={trade['entry_price']:.2f} exit={slipped_exit_price:.2f} "
            f"original_exit={exit_price:.2f} exit_slippage={trade.get('exit_slippage', 0):.4f} "
            f"total_slippage=${total_slippage:.4f} pnl=${pnl:.2f} reason={reason} result={win_or_loss}"
        )

    def get_balance(self) -> float:
        """Get current account balance."""
        return self.balance

    def get_trades(self) -> list[dict[str, Any]]:
        """Get all trades."""
        return self.trades.copy()

    def close_all_open_positions(self, final_price: float, final_time: Any) -> None:
        """Force close all open positions at backtest end.

        Args:
            final_price: Final market price to close positions at
            final_time: Final timestamp for closure
        """
        open_positions = [
            trade for trade in self.positions.values() if trade["status"] == "open"
        ]

        if not open_positions:
            return

        logger.info(
            f"Force closing {len(open_positions)} open positions at backtest end"
        )

        for trade in open_positions:
            self._close_trade(trade, final_price, final_time, "backtest_end")

        # Clear positions dict
        self.positions.clear()

        logger.info(f"All open positions closed. Final balance: ${self.balance:.2f}")

    def get_total_exposure(self) -> float:
        """Get total notional exposure of all open positions.

        Returns:
            Total dollar exposure across all open positions
        """
        total_exposure = 0.0
        for trade in self.positions.values():
            if trade["status"] == "open":
                notional = trade["size"] * trade["entry_price"]
                total_exposure += notional
        return total_exposure

    def get_open_position_count(self) -> int:
        """Get count of open positions."""
        return len(
            [trade for trade in self.positions.values() if trade["status"] == "open"]
        )

    def has_position_for_symbol(self, symbol: str) -> bool:
        """Check if there's already an open position for the symbol.

        Args:
            symbol: Trading symbol to check

        Returns:
            True if open position exists for symbol
        """
        for trade in self.positions.values():
            if trade["status"] == "open" and trade["symbol"] == symbol:
                return True
        return False

    def _validate_new_position(self, signal: TradingSignal, size: float) -> bool:
        """Validate if a new position can be opened.

        Args:
            signal: Trading signal
            size: Position size

        Returns:
            True if position can be opened
        """
        # Check concurrent position limit
        if self.get_open_position_count() >= self.max_concurrent_positions:
            logger.warning(
                f"Maximum concurrent positions reached: {self.max_concurrent_positions}"
            )
            return False

        # Check symbol duplicate limit
        if not self.allow_symbol_duplicates and self.has_position_for_symbol(
            signal.symbol
        ):
            logger.warning(f"Position already exists for symbol: {signal.symbol}")
            return False

        # Check total exposure limit
        position_value = size * signal.entry_price
        current_exposure = self.get_total_exposure()
        max_exposure = self.balance * self.max_exposure_pct

        if current_exposure + position_value > max_exposure:
            logger.warning(
                f"Position would exceed exposure limit: {current_exposure + position_value:.2f} > {max_exposure:.2f}"
            )
            return False

        return True

    def get_performance_stats(self) -> dict[str, Any]:
        """Get comprehensive performance statistics.

        Returns:
            Dictionary with performance metrics
        """
        closed_trades = [t for t in self.trades if t["status"] == "closed"]
        open_trades = [t for t in self.trades if t["status"] == "open"]

        # Basic trade statistics
        total_trades = len(self.trades)
        closed_count = len(closed_trades)
        open_count = len(open_trades)

        if closed_count == 0:
            return {
                "total_trades": total_trades,
                "closed_trades": closed_count,
                "open_trades": open_count,
                "total_pnl": 0.0,
                "win_rate": 0.0,
                "max_concurrent_positions": 0,
                "max_exposure": 0.0,
                "current_balance": self.balance,
            }

        # PnL calculation
        winning_trades = [t for t in closed_trades if t.get("pnl", 0) > 0]
        total_pnl = sum(t.get("pnl", 0) for t in closed_trades)
        win_rate = len(winning_trades) / closed_count if closed_count > 0 else 0.0

        # Position management statistics
        current_exposure = self.get_total_exposure()
        max_concurrent = 0
        max_exposure = 0.0

        # Calculate historical maximums (approximate)
        # For now, use current values as estimates
        max_concurrent = max(len(open_trades), self.max_concurrent_positions)
        max_exposure = max(
            current_exposure,
            sum(t.get("size", 0) * t.get("entry_price", 0) for t in self.trades),
        )

        return {
            "total_trades": total_trades,
            "closed_trades": closed_count,
            "open_trades": open_count,
            "winning_trades": len(winning_trades),
            "total_pnl": total_pnl,
            "win_rate": win_rate,
            "max_concurrent_positions": max_concurrent,
            "max_exposure": max_exposure,
            "current_balance": self.balance,
            "current_exposure": current_exposure,
        }


class IntegratedStrategy:
    """Integrated strategy that coordinates all Phase 1-7 components."""

    def __init__(
        self,
        config: Any,
        broker: MockPaperBroker,
        risk_manager: MockRiskManager | RiskManager,
        metrics_collector: MetricsCollector | None = None,
    ) -> None:
        """Initialize integrated strategy.

        Args:
            config: Strategy configuration
            broker: Paper broker instance
            risk_manager: Risk manager instance
            metrics_collector: Optional metrics collector for counters
        """
        self.config = config
        self.broker = broker
        self.risk_manager = risk_manager
        self.metrics_collector = metrics_collector

        # Initialize indicators with config values
        indicator_config = getattr(config, "indicators", {})
        data_config = getattr(config, "data", {})

        self.indicators = IndicatorPack(
            ema21_period=getattr(indicator_config, "ema21_period", 21),
            ema50_period=getattr(indicator_config, "ema50_period", 50),
            atr_period=getattr(indicator_config, "atr_period", 14),
            volume_sma_period=getattr(indicator_config, "volume_sma_period", 20),
            regime_sensitivity=getattr(indicator_config, "regime_sensitivity", 0.001),
            tick_size=getattr(data_config, "tick_size", 0.00001),
        )

        # Initialize strategy components based on strategy configuration
        logger.info(f"Config type: {type(config)}")
        logger.info(f"Strategy name: {getattr(config.strategy, 'name', 'NO_NAME')}")

        use_mock = getattr(config.strategy, "use_mock_strategy", False)

        # Validate mock component usage
        use_mock_components = getattr(config, "runtime", {}).get(
            "use_mock_components", True
        )
        if not use_mock_components and use_mock:
            raise ValueError(
                "Configuration error: runtime.use_mock_components is False but strategy.use_mock_strategy is True. "
                "Either enable mock components or disable mock strategy."
            )

        # Config validation
        if not use_mock:
            # Validate HLZ configuration when using real HTF strategy
            pivot_enabled = config.detectors.get("pivot", {}).get("enabled", False)
            hlz_min_members = config.hlz.get("min_members", 2)

            if not pivot_enabled and hlz_min_members > 2:
                logger.warning(
                    f"CONFIG SANITY: detectors.pivot.enabled == false but hlz.min_members = {hlz_min_members}. "
                    f"HLZ counts may be lower than expected with FVG-only detection. "
                    f"Consider setting hlz.min_members = 2 or enabling pivot detector."
                )

        if not use_mock and config.strategy.name.lower() == "htf_liquidity_mtf":
            # ── Build full HTF liquidity detection stack ────────────────────────────
            logger.info("Building real HTF liquidity strategy")

            # Initialize HTF stack container
            self.htf_stack = HTFStack()

            # Time aggregators (built first, used by detectors)
            self.htf_stack.time_aggregators = {}
            htf_list = getattr(config.strategy, "htf_list", ["H4", "D1"])
            for tf_name in htf_list:
                tf_minutes = (
                    240
                    if tf_name == "H4"
                    else 1440
                    if tf_name == "D1"
                    else int(tf_name[:-1])
                )
                aggregator = TimeAggregator(
                    tf_minutes=tf_minutes,
                    source_tf_minutes=config.aggregation.get("source_tf_minutes", 5),
                    buffer_size=config.aggregation.get("buffer_size", 1000),
                )
                self.htf_stack.time_aggregators[tf_name] = aggregator

            # Core registry and overlap detection
            from core.clock import get_clock

            from .overlap import OverlapConfig
            from .pool_registry import PoolRegistryConfig

            registry_config = PoolRegistryConfig(
                grace_period_minutes=config.pools["grace_period_minutes"],
                max_pools_per_tf=config.pools["max_pools_per_tf"],
            )

            # Initialize with simulation time for backtesting
            simulation_time = get_clock().now()
            logger.info(
                f"Factory creating PoolRegistry with simulation_time: {simulation_time}"
            )
            self.htf_stack.pool_registry = PoolRegistry(
                registry_config, current_time=simulation_time
            )

            overlap_config = OverlapConfig(
                min_members=config.hlz["min_members"],
                min_strength=config.hlz["min_strength"],
                tf_weight=config.hlz["tf_weight"],
                merge_tolerance=config.hlz["merge_tolerance"],
                side_mixing=config.hlz["side_mixing"],
            )
            self.htf_stack.overlap_detector = OverlapDetector(
                overlap_config, self.htf_stack.pool_registry
            )

            # Pool manager coordinates detector events → pools → HLZ
            from .pool_manager import PoolManagerConfig

            # Convert pool config from our YAML to PoolManagerConfig format
            ttl_by_timeframe = {}
            hit_tolerance_by_timeframe = {}

            # Parse pools config - convert from our timeframe keys to the expected format
            pools_config = getattr(config, "pools", {})
            strength_threshold = pools_config.get("strength_threshold", 0.1)

            # Parse auto expire interval string to timedelta
            auto_expire_str = pools_config.get("auto_expire_interval", "30s")
            if isinstance(auto_expire_str, str):
                if auto_expire_str.endswith("s"):
                    auto_expire_interval = timedelta(seconds=int(auto_expire_str[:-1]))
                elif auto_expire_str.endswith("m"):
                    auto_expire_interval = timedelta(minutes=int(auto_expire_str[:-1]))
                elif auto_expire_str.endswith("h"):
                    auto_expire_interval = timedelta(hours=int(auto_expire_str[:-1]))
                else:
                    auto_expire_interval = timedelta(seconds=30)  # default
            else:
                auto_expire_interval = timedelta(seconds=30)  # default

            # Convert individual timeframe configs (e.g., "240": {ttl: "3d", hit_tolerance: 0.0})
            for tf_str, tf_config in pools_config.items():
                if isinstance(tf_config, dict) and "ttl" in tf_config:
                    # Parse TTL string to timedelta
                    ttl_str = tf_config["ttl"]
                    if ttl_str.endswith("d"):
                        ttl = timedelta(days=int(ttl_str[:-1]))
                    elif ttl_str.endswith("h"):
                        ttl = timedelta(hours=int(ttl_str[:-1]))
                    elif ttl_str.endswith("m"):
                        ttl = timedelta(minutes=int(ttl_str[:-1]))
                    else:
                        ttl = timedelta(minutes=120)  # default

                    ttl_by_timeframe[tf_str] = ttl
                    hit_tolerance_by_timeframe[tf_str] = tf_config.get(
                        "hit_tolerance", 0.0
                    )

            pool_mgr_config = PoolManagerConfig(
                ttl_by_timeframe=ttl_by_timeframe,
                hit_tolerance_by_timeframe=hit_tolerance_by_timeframe,
                strength_threshold=strength_threshold,
                auto_expire_check_interval=auto_expire_interval,
                enable_event_logging=True,
            )
            self.htf_stack.pool_manager = PoolManager(
                self.htf_stack.pool_registry, pool_mgr_config, self.metrics_collector
            )

            # Zone watcher monitors pool/HLZ touches → signal candidates
            from .signal_candidate import CandidateConfig

            candidate_config = CandidateConfig(
                expiry_minutes=config.candidate["expiry_minutes"],
                ema_alignment=config.candidate["filters"]["ema_alignment"],
                ema_tolerance_pct=config.candidate["filters"].get(
                    "ema_tolerance_pct", 0.0
                ),
                linger_minutes=config.candidate["filters"].get("linger_minutes", 0),
                reclaim_requires_ema=config.candidate["filters"].get(
                    "reclaim_requires_ema", True
                ),
                volume_multiple=config.candidate["filters"]["volume_multiple"],
                killzone_start=config.candidate["filters"]["killzone"][0],
                killzone_end=config.candidate["filters"]["killzone"][1],
                regime_allowed=config.candidate["filters"]["regime"],
                # Enhanced killzone settings
                use_enhanced_killzone=config.candidate["filters"].get(
                    "use_enhanced_killzone", False
                ),
                killzone_sessions=config.candidate["filters"].get(
                    "killzone_sessions", None
                ),
                exclude_low_volume=config.candidate["filters"].get(
                    "exclude_low_volume", True
                ),
            )

            zone_config = ZoneWatcherConfig(
                price_tolerance=config.zone_watcher["price_tolerance"],
                confirm_closure=config.zone_watcher["confirm_closure"],
                min_strength=config.zone_watcher["min_strength"],
                max_active_zones=config.zone_watcher["max_active_zones"],
                # Entry spacing configuration from candidate section
                min_entry_spacing_minutes=config.candidate.get(
                    "min_entry_spacing_minutes", 30
                ),
                global_min_entry_spacing=config.candidate.get(
                    "global_min_entry_spacing", 10
                ),
                enable_spacing_throttle=config.candidate.get(
                    "enable_spacing_throttle", True
                ),
            )

            # Get timeframe - try data.timeframe first, fallback to deriving from aggregation
            timeframe = getattr(config.data, "timeframe", None)
            if timeframe is None:
                # Derive from aggregation.source_tf_minutes (5 minutes -> "5m")
                source_tf_minutes = config.aggregation.get("source_tf_minutes", 5)
                timeframe = f"{source_tf_minutes}m"

            self.htf_stack.zone_watcher = ZoneWatcher(
                zone_config,
                candidate_config,
                symbol=config.strategy.symbol,
                timeframe=str(timeframe),
            )

            # Wire PoolManager to notify ZoneWatcher of pool events
            self.htf_stack.pool_manager.zone_watcher = self.htf_stack.zone_watcher

            # Wire metrics collector to pool manager for counters
            if hasattr(self, "metrics_collector"):
                self.htf_stack.pool_manager.metrics_collector = self.metrics_collector

            # Detectors create liquidity pool events (with aggregator injection)
            self.htf_stack.detectors = []

            # Only create enabled detectors to save memory
            if config.detectors["fvg"]["enabled"]:
                # Create FVG detectors for each enabled timeframe
                htf_list = getattr(config.strategy, "htf_list", ["H4", "D1"])
                for tf in htf_list:
                    fvg_detector = FVGDetector(
                        tf=tf,
                        min_gap_atr=config.detectors["fvg"].get("min_gap_atr", 0.5),
                        min_gap_pct=config.detectors["fvg"].get("min_gap_pct", 0.001),
                        min_rel_vol=config.detectors["fvg"].get("min_rel_vol", 1.2),
                    )
                    self.htf_stack.detectors.append(fvg_detector)

            # Only create pivot detector if enabled
            if config.detectors.get("pivot", {}).get("enabled", False):
                logger.warning("Pivot detector requested but not implemented yet")
                # TODO: Add pivot detector when implemented
                # from .pivot_detector import PivotDetector
                # pivot_detector = PivotDetector(config.detectors["pivot"], self.htf_stack.pool_manager)
                # self.htf_stack.detectors.append(pivot_detector)

            # For backward compatibility, expose key components as attributes
            self.pool_registry = self.htf_stack.pool_registry
            self.zone_watcher = self.htf_stack.zone_watcher
            self.pool_manager = self.htf_stack.pool_manager
            self.detectors = self.htf_stack.detectors
            self.time_aggregators = self.htf_stack.time_aggregators

        else:
            # Fallback to mock for legacy/demo strategies
            if not use_mock_components:
                raise ValueError(
                    "Configuration error: Mock strategy requested but runtime.use_mock_components is False. "
                    "Either set runtime.use_mock_components to True or use a non-mock strategy."
                )

            logger.info("Using mock zone watcher (legacy mode)")
            # Create a simple FVG detector for 5-minute timeframe
            self.fvg_detector = FVGDetector(
                tf="5m", min_gap_atr=0.5, min_gap_pct=0.001, min_rel_vol=1.2
            )
            self.zone_watcher = MockZoneWatcher(config, risk_manager)
            # htf_stack is None for mock strategy

        # Metrics
        self.candles_processed = 0

    def shutdown(self) -> None:
        """Clean shutdown for all components."""
        if hasattr(self, "htf_stack") and self.htf_stack:
            self.htf_stack.shutdown()

    def on_candle(self, candle: Candle) -> None:
        """Process incoming candle through the full strategy pipeline.

        Args:
            candle: Market data candle
        """
        with measure_operation("strategy_on_candle"):
            self.candles_processed += 1

            # Advance simulation clock to candle time
            from core.clock import get_clock

            clock = get_clock()
            # For simulation clock, advance to candle time
            if hasattr(clock, "advance"):
                with suppress(ValueError):
                    # Handle backwards time during testing
                    clock.advance(candle.ts)

            # Process TTL expiries at current candle time
            if (
                hasattr(self, "htf_stack")
                and self.htf_stack
                and self.htf_stack.pool_registry
            ):
                try:
                    self.htf_stack.pool_registry.expire_due(candle.ts)
                except Exception as e:
                    # Log but don't fail the strategy
                    import logging

                    logger = logging.getLogger(__name__)
                    logger.debug(
                        f"TTL expiry processing failed: {e}"
                    )  # Update indicators
            with measure_operation("update_indicators"):
                self.indicators.update(candle)

            # Update FVG detector with ATR and volume SMA (for legacy mode)
            with measure_operation("update_detectors"):
                if not hasattr(self, "htf_stack") or not self.htf_stack:
                    # Only update legacy FVG detector in mock mode
                    atr_value = self.indicators.atr_value
                    vol_sma_value = self.indicators.volume_sma_value

                    # Only update FVG detector if we have indicator values
                    if atr_value is not None and vol_sma_value is not None:
                        self.fvg_detector.update(candle, atr_value, vol_sma_value)

            # Update broker positions first
            with measure_operation("update_positions"):
                self.broker.update_positions(candle)

            # Process strategy based on type
            with measure_operation("check_signals"):
                if hasattr(self, "htf_stack") and self.htf_stack:
                    # Real HTF strategy workflow
                    signal = self._process_htf_strategy(candle)
                else:
                    # Mock strategy workflow
                    signal = self.zone_watcher.update(candle, self.indicators)

                if signal:
                    # Size position with risk manager
                    size = self.risk_manager.size_position(
                        signal, self.broker.get_balance()
                    )

                    if size > 0:
                        # Submit order to broker
                        self.broker.submit_order(signal, size)

    def _process_htf_strategy(self, candle: Candle) -> Any:
        """Process real HTF liquidity strategy workflow.

        Args:
            candle: Current 5-minute source candle

        Returns:
            TradingSignal if conditions met, None otherwise
        """
        # 0. Update existing positions with current market data
        self.broker.update_positions(candle)

        # 1. Update time aggregators - generates HTF candles
        all_htf_candles = []
        for tf_name, aggregator in self.time_aggregators.items():
            htf_candles = aggregator.update(candle)
            if htf_candles:
                logger.info(
                    f"HTF Strategy: Generated {len(htf_candles)} {tf_name}m candles"
                )
                # Debug: Log each candle returned
                for i, htf_candle in enumerate(htf_candles):
                    logger.info(
                        f"  HTF candle {i}: {htf_candle.ts} OHLC={htf_candle.open:.1f}/{htf_candle.high:.1f}/{htf_candle.low:.1f}/{htf_candle.close:.1f}"
                    )
            for htf_candle in htf_candles:
                all_htf_candles.append((tf_name, htf_candle))

        # 2. Process each HTF candle through detectors
        for tf_name, htf_candle in all_htf_candles:
            logger.info(
                f"HTF Strategy: Processing {tf_name}m candle at {htf_candle.ts}"
            )
            atr_value = self.indicators.atr_value
            vol_sma_value = self.indicators.volume_sma_value

            logger.info(f"  ATR value: {atr_value}, Vol SMA value: {vol_sma_value}")

            if atr_value is not None and vol_sma_value is not None:
                # Run detectors matching this timeframe
                for detector in self.detectors:
                    if hasattr(detector, "tf") and detector.tf == tf_name:
                        logger.info(
                            f"  Running detector {type(detector).__name__} for {tf_name}"
                        )

                        # Check buffer state before processing
                        if hasattr(detector, "_buffer"):
                            logger.info(
                                f"  Detector buffer size before: {len(detector._buffer)}"
                            )
                            for i, buf_candle in enumerate(detector._buffer):
                                logger.info(
                                    f"    Buffer[{i}]: {buf_candle.ts} OHLC({buf_candle.open:.1f}, {buf_candle.high:.1f}, {buf_candle.low:.1f}, {buf_candle.close:.1f})"
                                )

                        events = detector.update(htf_candle, atr_value, vol_sma_value)
                        logger.info(f"  Detector returned {len(events)} events")

                        # Check buffer state after processing
                        if hasattr(detector, "_buffer"):
                            logger.info(
                                f"  Detector buffer size after: {len(detector._buffer)}"
                            )
                            for i, buf_candle in enumerate(detector._buffer):
                                logger.info(
                                    f"    Buffer[{i}]: {buf_candle.ts} OHLC({buf_candle.open:.1f}, {buf_candle.high:.1f}, {buf_candle.low:.1f}, {buf_candle.close:.1f})"
                                )

                        if events:
                            logger.info(
                                f"HTF Strategy: FVG detector found {len(events)} events in {tf_name}m"
                            )
                            for i, event in enumerate(events):
                                logger.info(f"    Event {i}: {event}")

                        # Process events through pool manager
                        if (
                            events
                            and hasattr(self, "pool_manager")
                            and self.pool_manager
                        ):
                            for event in events:
                                logger.info(
                                    f"  Processing event through pool manager: {event.pool_id}"
                                )
                                result = self.pool_manager.process_detector_event(event)
                                logger.info(
                                    f"  Pool manager result: success={result.success}, pool_created={result.pool_created}"
                                )
                                if result.success and result.pool_created:
                                    logger.info(
                                        f"HTF Strategy: Created pool {result.pool_id} from {tf_name} FVG"
                                    )
                    else:
                        logger.info(
                            f"  Skipping detector {type(detector).__name__} (tf={getattr(detector, 'tf', 'NO_TF')} != {tf_name})"
                        )
            else:
                logger.info(
                    "  Skipping detector processing - ATR or Vol SMA not available"
                )

        # 3. Check zone watcher for price entries using current 5m candle
        zone_entries = self.zone_watcher.on_price_update(candle)

        # 4. Process any zone entries through signal candidate FSM
        for zone_entry in zone_entries:
            candidate = self.zone_watcher.spawn_candidate(zone_entry, candle.ts)
            logger.debug(
                f"Spawned candidate {candidate.candidate_id} from zone {zone_entry.zone_id}"
            )

        # 5. Run candidate FSM for all active candidates
        if hasattr(self.zone_watcher, "active_candidates"):
            updated_candidates = []

            for candidate in self.zone_watcher.active_candidates:
                # Create indicator snapshot for FSM processing
                snapshot = self.indicators.snapshot()

                # Update candidate with current bar and indicators using FSM
                updated_candidate = candidate.update(
                    candle, snapshot, self.zone_watcher.candidate_fsm
                )

                # Skip if update returned None (should not happen but defensive coding)
                if updated_candidate is None:
                    logger.warning(
                        f"Candidate update returned None for {candidate.candidate_id}"
                    )
                    continue

                # Check if candidate is ready for trading
                if updated_candidate.is_ready():
                    # Check entry spacing at READY time to prevent duplicate orders
                    candle_ts_ms = int(candle.ts.timestamp() * 1000)

                    if self.zone_watcher.within_spacing(
                        updated_candidate.zone_id, candle_ts_ms
                    ):
                        # Throttle this candidate - mark as spaced out
                        spaced_candidate = updated_candidate.mark_spaced()
                        updated_candidates.append(spaced_candidate)

                        logger.debug(
                            f"Throttle READY on pool {updated_candidate.zone_id} - entry spacing active"
                        )

                        # Track throttling metrics
                        if (
                            hasattr(self, "metrics_collector")
                            and self.metrics_collector
                        ):
                            self.metrics_collector.increment_counter("trades_throttled")

                        continue

                    # All spacing checks passed - proceed with order submission
                    # Convert candidate to trading signal with proper timestamp
                    # Get timeframe safely
                    timeframe = getattr(self.config.data, "timeframe", None)
                    if timeframe is None:
                        source_tf_minutes = self.config.aggregation.get(
                            "source_tf_minutes", 5
                        )
                        timeframe = f"{source_tf_minutes}m"

                    signal = updated_candidate.to_signal(
                        symbol=self.config.strategy.symbol,
                        timeframe=str(timeframe),
                        current_price=snapshot.current_close,
                        filters_passed=4,  # TODO: Track actual filter results in FSM
                        total_filters=5,  # TODO: Get from FSM configuration
                        entry_timestamp=candle.ts,
                    )
                    logger.info(
                        f"Generated trading signal from candidate {updated_candidate.candidate_id}"
                    )
                    logger.debug(
                        f"Signal details: entry={signal.entry_price}, stop_loss={signal.stop_loss}, side={signal.side}"
                    )

                    # Record signal emission metrics
                    if hasattr(self, "metrics_collector") and self.metrics_collector:
                        self.metrics_collector.increment_signals_emitted()

                    # Size position with risk manager
                    size = self.risk_manager.size_position(
                        signal, self.broker.get_balance()
                    )
                    logger.debug(
                        f"Position size calculated: {size}, account_balance: {self.broker.get_balance()}"
                    )

                    if size > 0:
                        # Submit order to broker
                        trade_id = self.broker.submit_order(signal, size)

                        # Register trade execution immediately for spacing tracking
                        self.zone_watcher.register_trade(
                            updated_candidate.zone_id, candle_ts_ms
                        )

                        logger.info(
                            f"Submitted order {trade_id} from candidate {updated_candidate.candidate_id}"
                        )

                        # Mark candidate as submitted
                        if hasattr(updated_candidate, "mark_submitted"):
                            updated_candidate.mark_submitted(trade_id)

                    # Remove candidate after signal generation (don't add to updated_candidates)
                    # This prevents duplicate signals from the same candidate
                    logger.debug(
                        f"Removing candidate {updated_candidate.candidate_id} after signal generation"
                    )

                # Clean up expired candidates
                elif (
                    hasattr(updated_candidate, "state")
                    and str(updated_candidate.state).upper() == "EXPIRED"
                ):
                    logger.debug(
                        f"Removing expired candidate {updated_candidate.candidate_id}"
                    )

                    # Record candidate expiration metrics
                    if hasattr(self, "metrics_collector") and self.metrics_collector:
                        self.metrics_collector.record_candidate_expired()

                    # Don't add to updated_candidates (effectively removes it)

                else:
                    # Keep active candidates that aren't ready or expired
                    updated_candidates.append(updated_candidate)

            # Replace the candidates list with updated ones
            self.zone_watcher.active_candidates = updated_candidates

        return None

    def on_backtest_complete(self, final_candle: Candle) -> None:
        """Handle backtest completion - force close all open positions.

        Args:
            final_candle: The final market candle of the backtest
        """
        if hasattr(self.broker, "close_all_open_positions"):
            self.broker.close_all_open_positions(final_candle.close, final_candle.ts)

    def get_performance_stats(self) -> dict[str, Any]:
        """Get comprehensive performance statistics."""
        stats = {}

        # Get broker stats
        if hasattr(self.broker, "get_performance_stats"):
            broker_stats = self.broker.get_performance_stats()
            stats.update(broker_stats)

        # Add strategy-specific stats
        stats.update(
            {
                "candles_processed": self.candles_processed,
                "total_signals": getattr(self, "total_signals", 0),
            }
        )

        # Get metrics from collector if available
        if hasattr(self, "metrics_collector") and self.metrics_collector:
            collector_stats = self.metrics_collector.get_summary()
            stats.update(collector_stats)

        return stats


class StrategyFactory:
    """Factory for building complete strategy instances from configuration."""

    @staticmethod
    def build(
        config: Any,
        metrics_collector: MetricsCollector | None = None,
        shared_risk_manager: RiskManager | None = None,
    ) -> IntegratedStrategy:
        """Build complete strategy from configuration.

        Args:
            config: Strategy configuration
            metrics_collector: Optional metrics collector
            shared_risk_manager: Optional shared risk manager for ATR warm-up reuse

        Returns:
            Configured IntegratedStrategy instance
        """
        logger.info(f"Building strategy for symbol: {config.strategy.symbol}")

        # Validate mock component usage
        use_mock_components = getattr(config, "runtime", {}).get(
            "use_mock_components", True
        )

        if not use_mock_components:
            raise ValueError(
                "Configuration error: runtime.use_mock_components is False but StrategyFactory.build() "
                "only supports mock components. Use a production factory for live trading."
            )

        # Create broker with metrics collector
        broker = MockPaperBroker(config, metrics_collector)

        # Create or reuse risk manager for ATR warm-up caching
        if shared_risk_manager is not None:
            risk_manager = shared_risk_manager
            logger.debug("Reusing shared risk manager for ATR warm-up")
        else:
            # Create real RiskManager with proper configuration
            from core.risk.config import RiskConfig

            # Handle different config structures - prefer execution.risk, fallback to top-level risk
            risk_section = None

            # First, try to get from execution.risk (the primary location)
            if hasattr(config, "execution") and hasattr(config.execution, "risk"):
                risk_section = config.execution.risk
                logger.info(
                    f"Found risk section in execution.risk: tp_rr={getattr(risk_section, 'tp_rr', 'NOT_FOUND')}"
                )
            # Fallback to top-level risk section
            elif hasattr(config, "risk"):
                risk_section = config.risk
                logger.info(
                    f"Found risk section in config.risk: tp_rr={getattr(risk_section, 'tp_rr', 'NOT_FOUND')}"
                )
            else:
                logger.warning("No risk configuration found, using defaults")

            # Handle missing fields with defaults
            risk_config = RiskConfig(
                model=RiskModel.ATR
                if (risk_section and getattr(risk_section, "model", "atr") == "atr")
                else RiskModel.PERCENT,
                risk_per_trade=getattr(risk_section, "risk_per_trade", 0.005)
                if risk_section
                else 0.005,
                atr_period=getattr(risk_section, "atr_period", 14)
                if risk_section
                else 14,
                sl_atr_multiple=getattr(risk_section, "sl_atr_multiple", 1.5)
                if risk_section
                else 1.5,
                tp_rr=getattr(risk_section, "tp_rr", 2.0) if risk_section else 2.0,
                min_position=getattr(risk_section, "min_position", 0.01)
                if risk_section
                else 0.01,
                max_position_pct=getattr(risk_section, "max_position_pct", 0.1)
                if risk_section
                else 0.1,
            )
            logger.info(f"Created RiskConfig with tp_rr={risk_config.tp_rr}")
            risk_manager = RiskManager(risk_config)

        # Create integrated strategy
        strategy = IntegratedStrategy(config, broker, risk_manager, metrics_collector)

        logger.info("Strategy factory build complete")
        return strategy

    @staticmethod
    def create_test_signal(symbol: str = "BTCUSDT") -> TradingSignal:
        """Create a test trading signal for acceptance testing.

        Args:
            symbol: Trading symbol

        Returns:
            Test TradingSignal
        """
        from datetime import datetime

        return TradingSignal(
            symbol=symbol,
            side="buy",
            entry_price=50000.0,
            stop_loss=49000.0,
            take_profit=52000.0,
            size=100.0,
            timestamp=datetime.now(),
            reason="test_signal",
        )
